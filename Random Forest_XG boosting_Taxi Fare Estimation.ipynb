{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be4fd1e4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.3-py3-none-win_amd64.whl (99.8 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\yorgh\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\yorgh\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36f700db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,\\\n",
    "f1_score, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "from sklearn.metrics import make_scorer, r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# This is the function that helps plot feature importance \n",
    "from xgboost import plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcd1c45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL TO SEE ALL COLUMNS \n",
    "# This lets us see all of the columns, preventing Juptyer from redacting them.\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70c73e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\yorgh\\Documents\\Course Materials\\Google Advanced Data Analytics Course\\Datasets Exercise\\Automatidata project\\2017_Yellow_Taxi_Trip_Features_engineering(2).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edc898e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>duration</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>rush_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.34</td>\n",
       "      <td>14.066667</td>\n",
       "      <td>13.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.80</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>16.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>7.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.70</td>\n",
       "      <td>30.250000</td>\n",
       "      <td>21.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.37</td>\n",
       "      <td>16.716667</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21917</th>\n",
       "      <td>0.89</td>\n",
       "      <td>9.450000</td>\n",
       "      <td>8.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21918</th>\n",
       "      <td>0.61</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21919</th>\n",
       "      <td>0.42</td>\n",
       "      <td>4.133333</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21920</th>\n",
       "      <td>2.36</td>\n",
       "      <td>11.933333</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21921</th>\n",
       "      <td>2.10</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21922 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       trip_distance   duration  total_amount  rush_hour\n",
       "0               3.34  14.066667          13.8          0\n",
       "1               1.80  26.500000          16.8          0\n",
       "2               1.00   7.200000           7.3          1\n",
       "3               3.70  30.250000          21.3          0\n",
       "4               4.37  16.716667          17.8          0\n",
       "...              ...        ...           ...        ...\n",
       "21917           0.89   9.450000           8.8          0\n",
       "21918           0.61   3.266667           5.8          1\n",
       "21919           0.42   4.133333           5.3          0\n",
       "21920           2.36  11.933333          11.3          0\n",
       "21921           2.10  13.333333          11.8          0\n",
       "\n",
       "[21922 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7341e743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate target variable (y)\n",
    "y = df['total_amount']\n",
    "\n",
    "# Isolate the features (X)\n",
    "X = df.drop('total_amount', axis=1)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Split train into tr and val sets\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a50fb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instantiate the random forest regressor\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# 2. Create a dictionary of hyperparameters to tune \n",
    "cv_params = {'max_depth': [None],\n",
    "             'max_features': [1.0],\n",
    "             'max_samples': [0.7],\n",
    "             'min_samples_leaf': [1],\n",
    "             'min_samples_split': [2],\n",
    "             'n_estimators': [300]\n",
    "             }\n",
    "\n",
    "# Define a set of scoring metrics to capture\n",
    "scoring = {'r2': make_scorer(r2_score),\n",
    "           'neg_mean_absolute_error': make_scorer(mean_absolute_error, greater_is_better=False), # negate for GridSearchCV\n",
    "           'neg_mean_squared_error': make_scorer(mean_squared_error, greater_is_better=False), # negate for GridSearchCV\n",
    "           'neg_root_mean_squared_error': make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False), greater_is_better=False) # negate for GridSearchCV\n",
    "          }\n",
    "\n",
    "# 4. Instantiate the GridSearchCV object\n",
    "rf_grid = GridSearchCV(rf, cv_params, scoring=scoring, cv=3, refit='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cc3a84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 12 s\n",
      "Wall time: 17.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestRegressor(random_state=42),\n",
       "             param_grid={'max_depth': [None], 'max_features': [1.0],\n",
       "                         'max_samples': [0.7], 'min_samples_leaf': [1],\n",
       "                         'min_samples_split': [2], 'n_estimators': [300]},\n",
       "             refit='r2',\n",
       "             scoring={'neg_mean_absolute_error': make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "                      'neg_mean_squared_error': make_scorer(mean_squared_error, greater_is_better=False),\n",
       "                      'neg_root_mean_squared_error': make_scorer(<lambda>, greater_is_better=False),\n",
       "                      'r2': make_scorer(r2_score)})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf_grid.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8a8cbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9799422137283056"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine best score\n",
    "rf_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fb61c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'max_features': 1.0,\n",
       " 'max_samples': 0.7,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a30d32b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_results(model_name:str, model_object, metric:str):\n",
    "    '''\n",
    "    Arguments:\n",
    "    model_name (string): what you want the model to be called in the output table\n",
    "    model_object: a fit GridSearchCV object\n",
    "    metric (string): r2, MAE, MSE, or RMSE\n",
    "\n",
    "    Returns a pandas df with the R-squared, MAE, MSE, and RMSE scores\n",
    "    for the model with the best mean 'metric' score across all validation folds.\n",
    "    '''\n",
    "\n",
    "    # Create dictionary that maps input metric to actual metric name in GridSearchCV\n",
    "    metric_dict = {'r2': 'mean_test_r2',\n",
    "                   'MAE': 'mean_test_neg_mean_absolute_error',\n",
    "                   'MSE': 'mean_test_neg_mean_squared_error',\n",
    "                   'RMSE': 'mean_test_neg_root_mean_squared_error',\n",
    "                   }\n",
    "\n",
    "    # Get all the results from the CV and put them in a df\n",
    "    cv_results = pd.DataFrame(model_object.cv_results_)\n",
    "\n",
    "    # Isolate the row of the df with the max(metric) score\n",
    "    best_estimator_results = cv_results.iloc[cv_results[metric_dict[metric]].idxmax(), :]\n",
    "\n",
    "    # Extract R-squared, MAE, MSE, and RMSE scores from that row\n",
    "    r2 = best_estimator_results.mean_test_r2\n",
    "    MAE = -best_estimator_results.mean_test_neg_mean_absolute_error  # negate back\n",
    "    MSE = -best_estimator_results.mean_test_neg_mean_squared_error  # negate back\n",
    "    RMSE = -best_estimator_results.mean_test_neg_root_mean_squared_error  # negate back\n",
    "\n",
    "    # Create table of results\n",
    "    table = pd.DataFrame({'model': [model_name],\n",
    "                          'R-squared': [r2],\n",
    "                          'MAE': [MAE],\n",
    "                          'MSE': [MSE],\n",
    "                          'RMSE': [RMSE],\n",
    "                         })\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd1e6200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>R-squared</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF CV</td>\n",
       "      <td>0.979942</td>\n",
       "      <td>0.527675</td>\n",
       "      <td>1.373694</td>\n",
       "      <td>1.171614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  R-squared       MAE       MSE      RMSE\n",
       "0  RF CV   0.979942  0.527675  1.373694  1.171614"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call 'make_results()' on the GridSearch object\n",
    "results = make_results('RF CV', rf_grid, 'r2')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8902553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Instantiate the XGBoost regressor\n",
    "xgb = XGBRegressor(objective='reg:squarederror', random_state=0)\n",
    "\n",
    "# 2. Create a dictionary of hyperparameters to tune \n",
    "cv_params = {'learning_rate': [0.1,0.3,0.5],\n",
    "             'max_depth': [None,10,7],\n",
    "             'min_child_weight': [2,1,3],\n",
    "             'n_estimators': [300]\n",
    "             }\n",
    "\n",
    "# 3. Define a set of scoring metrics to capture\n",
    "scoring = {'r2': make_scorer(r2_score),\n",
    "           'neg_mean_absolute_error': make_scorer(mean_absolute_error, greater_is_better=False), # negate for GridSearchCV\n",
    "           'neg_mean_squared_error': make_scorer(mean_squared_error, greater_is_better=False), # negate for GridSearchCV\n",
    "           'neg_root_mean_squared_error': make_scorer(lambda y_true, y_pred: mean_squared_error(y_true, y_pred, squared=False), greater_is_better=False) # negate for GridSearchCV\n",
    "          }\n",
    "\n",
    "# 4. Instantiate the GridSearchCV object\n",
    "xgb1 = GridSearchCV(xgb, cv_params, scoring=scoring, cv=3, refit='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "14c92e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 15s\n",
      "Wall time: 23.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, device=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                         'max_depth': [None, 10, 7],\n",
       "                         'min_child_weight': [2, 1, 3], 'n_estimators': [300]},\n",
       "             refit='r2',\n",
       "             scoring={'neg_mean_absolute_error': make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "                      'neg_mean_squared_error': make_scorer(mean_squared_error, greater_is_better=False),\n",
       "                      'neg_root_mean_squared_error': make_scorer(<lambda>, greater_is_better=False),\n",
       "                      'r2': make_scorer(r2_score)})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "xgb1.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "98ea8efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9758201045676627"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine best score\n",
    "xgb1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "58cf56ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1,\n",
       " 'max_depth': None,\n",
       " 'min_child_weight': 1,\n",
       " 'n_estimators': 300}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine best parameters\n",
    "xgb1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6168b09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>R-squared</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF CV</td>\n",
       "      <td>0.979942</td>\n",
       "      <td>0.527675</td>\n",
       "      <td>1.373694</td>\n",
       "      <td>1.171614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB CV</td>\n",
       "      <td>0.975820</td>\n",
       "      <td>0.547007</td>\n",
       "      <td>1.654026</td>\n",
       "      <td>1.286033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model  R-squared       MAE       MSE      RMSE\n",
       "0   RF CV   0.979942  0.527675  1.373694  1.171614\n",
       "0  XGB CV   0.975820  0.547007  1.654026  1.286033"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call 'make_results()' on the GridSearch object\n",
    "xgb1_cv_results = make_results('XGB CV', xgb1, 'r2')\n",
    "results = pd.concat([results, xgb1_cv_results], axis=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c32b1060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performing model: Random Forest\n",
      "MSE of best performing model: 1.4115460492959693\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "# Define base learners\n",
    "base_learners = {\n",
    "    \"Linear Regression\": (LinearRegression(), None),\n",
    "    \"Random Forest\": (RandomForestRegressor(random_state=42), {'n_estimators': [100, 200, 300],\n",
    "                                                              'max_depth': [None, 10, 20]}),\n",
    "    \"XGBoost\": (XGBRegressor(objective='reg:squarederror', random_state=42), None)\n",
    "}\n",
    "\n",
    "# Train and evaluate each base learner\n",
    "predictions = {}\n",
    "for name, (model, param_grid) in base_learners.items():\n",
    "    # Perform hyperparameter tuning if param_grid is not empty\n",
    "    if param_grid:\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "        grid_search.fit(X_tr, y_tr)\n",
    "        model = grid_search.best_estimator_\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_tr, y_tr)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    if name == \"Linear Regression\":\n",
    "        # For linear regression, we use cross-validation\n",
    "        y_pred = cross_val_predict(model, X_tr, y_tr, cv=5)\n",
    "        mse = mean_squared_error(y_tr, y_pred)\n",
    "    else:\n",
    "        # For other models, we use holdout set\n",
    "        y_pred = model.predict(X_val)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "    \n",
    "    predictions[name] = {'predictions': y_pred, 'mse': mse}\n",
    "\n",
    "# Select the best performing model\n",
    "best_model_name = min(predictions, key=lambda k: predictions[k]['mse'])\n",
    "best_model_predictions = predictions[best_model_name]['predictions']\n",
    "best_model_mse = predictions[best_model_name]['mse']\n",
    "\n",
    "print(\"Best performing model:\", best_model_name)\n",
    "print(\"MSE of best performing model:\", best_model_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d4128722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performing model: Random Forest\n",
      "MSE of best performing model: 1.4115460492959693\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define base learners with hyperparameter grids for tuning\n",
    "base_learners = {\n",
    "    \"Linear Regression\": (LinearRegression(), {}),\n",
    "    \"Random Forest\": (RandomForestRegressor(random_state=42), {'n_estimators': [100, 200, 300],\n",
    "                                                              'max_depth': [None, 10, 20]}),\n",
    "    \"XGBoost\": (XGBRegressor(objective='reg:squarederror', random_state=42), {'n_estimators': [100, 200, 300],\n",
    "                                                                               'max_depth': [3, 5, 7],\n",
    "                                                                               'learning_rate': [0.1, 0.01]})\n",
    "}\n",
    "\n",
    "# Train and evaluate each base learner\n",
    "predictions = {}\n",
    "for name, (model, param_grid) in base_learners.items():\n",
    "    # Perform hyperparameter tuning if param_grid is not empty\n",
    "    if param_grid:\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "        grid_search.fit(X_tr, y_tr)\n",
    "        model = grid_search.best_estimator_\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_tr, y_tr)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    if name == \"Linear Regression\":\n",
    "        # For linear regression, we use cross-validation\n",
    "        y_pred = cross_val_predict(model, X_val, y_val, cv=5)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "    else:\n",
    "        # For other models, we use holdout set\n",
    "        y_pred = model.predict(X_val)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "    \n",
    "    predictions[name] = {'predictions': y_pred, 'mse': mse}\n",
    "\n",
    "# Select the best performing model\n",
    "best_model_name = min(predictions, key=lambda k: predictions[k]['mse'])\n",
    "best_model_predictions = predictions[best_model_name]['predictions']\n",
    "best_model_mse = predictions[best_model_name]['mse']\n",
    "\n",
    "print(\"Best performing model:\", best_model_name)\n",
    "print(\"MSE of best performing model:\", best_model_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2beb7076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yorgh\\AppData\\Local\\Temp\\ipykernel_11544\\3667759675.py:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'Model': name,\n",
      "C:\\Users\\yorgh\\AppData\\Local\\Temp\\ipykernel_11544\\3667759675.py:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'Model': name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "               Model                                    Best Parameters  \\\n",
      "0  Linear Regression                                               None   \n",
      "1      Random Forest             {'max_depth': 10, 'n_estimators': 300}   \n",
      "2            XGBoost  {'learning_rate': 0.1, 'max_depth': 3, 'n_esti...   \n",
      "\n",
      "  R-squared Train MAE Train MSE Train RMSE Train R-squared Test  MAE Test  \\\n",
      "0        0.978263  0.582476   1.48801    1.21984        0.97886  0.564972   \n",
      "1        0.992325  0.390374  0.525415   0.724855       0.980358  0.505911   \n",
      "2        0.981917  0.513106  1.237904   1.112612         0.9798  0.538363   \n",
      "\n",
      "   MSE Test RMSE Test  \n",
      "0  1.519166  1.232545  \n",
      "1  1.411546  1.188085  \n",
      "2    1.4516  1.204824  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yorgh\\AppData\\Local\\Temp\\ipykernel_11544\\3667759675.py:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append({'Model': name,\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_model_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 74>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResults:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_df)\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mbest_model_params\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model_params' is not defined"
     ]
    }
   ],
   "source": [
    "# Define base learners with hyperparameter grids for tuning\n",
    "base_learners = {\n",
    "    \"Linear Regression\": (LinearRegression(), {}),\n",
    "    \"Random Forest\": (RandomForestRegressor(random_state=42), {'n_estimators': [100, 200, 300],\n",
    "                                                              'max_depth': [None, 10, 20]}),\n",
    "    \"XGBoost\": (XGBRegressor(objective='reg:squarederror', random_state=42), {'n_estimators': [100, 200, 300],\n",
    "                                                                               'max_depth': [3, 5, 7],\n",
    "                                                                               'learning_rate': [0.1, 0.01]})\n",
    "}\n",
    "# Define a function to calculate RMSE\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Initialize a DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Best Parameters', 'R-squared Train', 'MAE Train', 'MSE Train', 'RMSE Train',\n",
    "                                   'R-squared Test', 'MAE Test', 'MSE Test', 'RMSE Test'])\n",
    "\n",
    "# Train and evaluate each base learner\n",
    "for name, (model, param_grid) in base_learners.items():\n",
    "    # Perform hyperparameter tuning if param_grid is not empty\n",
    "    if param_grid:\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "        grid_search.fit(X_tr, y_tr)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "    else:\n",
    "        best_model = model\n",
    "        best_params = None\n",
    "    \n",
    "    # Train the model\n",
    "    best_model.fit(X_tr, y_tr)\n",
    "    \n",
    "    # Evaluate the model on train data\n",
    "    y_train_pred = best_model.predict(X_tr)\n",
    "    r2_train = r2_score(y_tr, y_train_pred)\n",
    "    mae_train = mean_absolute_error(y_tr, y_train_pred)\n",
    "    mse_train = mean_squared_error(y_tr, y_train_pred)\n",
    "    rmse_train = calculate_rmse(y_tr, y_train_pred)\n",
    "    \n",
    "    # Evaluate the model on test data\n",
    "    y_test_pred = best_model.predict(X_val)\n",
    "    r2_test = r2_score(y_val, y_test_pred)\n",
    "    mae_test = mean_absolute_error(y_val, y_test_pred)\n",
    "    mse_test = mean_squared_error(y_val, y_test_pred)\n",
    "    rmse_test = calculate_rmse(y_val, y_test_pred)\n",
    "    \n",
    "    # Store results in DataFrame\n",
    "    results_df = results_df.append({'Model': name,\n",
    "                                    'Best Parameters': best_params,\n",
    "                                    'R-squared Train': r2_train,\n",
    "                                    'MAE Train': mae_train,\n",
    "                                    'MSE Train': mse_train,\n",
    "                                    'RMSE Train': rmse_train,\n",
    "                                    'R-squared Test': r2_test,\n",
    "                                    'MAE Test': mae_test,\n",
    "                                    'MSE Test': mse_test,\n",
    "                                    'RMSE Test': rmse_test}, ignore_index=True)\n",
    "    \n",
    "# # Convert 'MSE Train' column to numeric dtype\n",
    "# results_df['MSE Train'] = pd.to_numeric(results_df['MSE Train'])\n",
    "# # Print best performing model on train data\n",
    "# print(\"Best performing model on train data:\")\n",
    "# print(results_df.loc[results_df['MSE Train'].idxmin()])\n",
    "\n",
    "# # Convert 'MSE Train' column to numeric dtype\n",
    "# results_df['MSE Test'] = pd.to_numeric(results_df['MSE Test'])\n",
    "# # Print best performing model on test data\n",
    "# print(\"\\nBest performing model on test data:\")\n",
    "# print(results_df.loc[results_df['MSE Test'].idxmin()])\n",
    "\n",
    "# Print results table\n",
    "print(\"\\nResults:\")\n",
    "print(results_df)\n",
    "# print(\"Best parameters:\", best_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bf67a153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1.48801\n",
      "1    0.525415\n",
      "2    1.237904\n",
      "Name: MSE Train, dtype: object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "print(results_df['MSE Train'].head())\n",
    "print(results_df['MSE Train'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92241b02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
